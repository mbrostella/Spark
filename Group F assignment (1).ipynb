{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PySpark environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark3/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data source and Spark data abstraction (DataFrame) setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "CA_DF = spark.read \\\n",
    "                 .option(\"inferSchema\", \"true\") \\\n",
    "                 .option(\"header\", \"true\") \\\n",
    "                 .csv(\"CAvideos2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data set metadata analysis\n",
    "### A. Display schema and size of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- publish_time: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: string (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- dislikes: string (nullable = true)\n",
      " |-- comment_count: string (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- comments_disabled: string (nullable = true)\n",
      " |-- ratings_disabled: string (nullable = true)\n",
      " |-- video_error_or_removed: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This DataFrame has **45560 rows**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "CA_DF.printSchema()\n",
    "display(Markdown(\"This DataFrame has **%d rows**.\" % CA_DF.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Define a Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the data source schema, we are going to create a new schema to reflect more accurately some columns, and make data analysis smoother. Additionally, we plan to combine USA, MEXICO, and CANADA data into one DF for North America data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, BooleanType, DateType, TimestampType\n",
    "\n",
    "NASchema = StructType(\\\n",
    "     [StructField(\"video_id\",StringType(),True),\\\n",
    "     StructField(\"trending_date\",StringType(),True),\\\n",
    "     StructField(\"title\",StringType(),True),\\\n",
    "     StructField(\"channel_title\",StringType(),True),\\\n",
    "     StructField(\"category_id\",IntegerType(),True),\\\n",
    "     StructField(\"publish_time\",TimestampType(),True),\\\n",
    "     StructField(\"tags\",StringType(),True),\\\n",
    "     StructField(\"views\",IntegerType(),True),\\\n",
    "     StructField(\"likes\",IntegerType(),True),\\\n",
    "     StructField(\"dislikes\",IntegerType(),True),\\\n",
    "     StructField(\"comment_count\",IntegerType(),True),\\\n",
    "     StructField(\"thumbnail_link\",StringType(),True),\\\n",
    "     StructField(\"comments_disabled\",BooleanType(),True),\\\n",
    "     StructField(\"ratings_disabled\",BooleanType(),True),\\\n",
    "     StructField(\"video_error_or_removed\",BooleanType(),True),\\\n",
    "     StructField(\"description\",StringType(),True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STILL NEED TO CONVERT STRINGS TO DATE TYPE FORMAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(video_id='n1WpP7iowLc', trending_date='17.14.11', title='Eminem - Walk On Water (Audio) ft. Beyoncé', channel_title='EminemVEVO', category_id=10, publish_time=datetime.datetime(2017, 11, 10, 18, 0, 3), tags='\"Eminem\"|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/Interscope\"|\"Rap\"', views=17158579, likes=787425, dislikes=43420, comment_count=125882, thumbnail_link='https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg', comments_disabled=False, ratings_disabled=False, video_error_or_removed=False, description=\"Eminem's new track Walk on Water ft. Beyoncé is available everywhere: http://shady.sr/WOWEminem \\\\nPlaylist Best of Eminem: https://goo.gl/AquNpo\\\\nSubscribe for more: https://goo.gl/DxCrDV\\\\n\\\\nFor more visit: \\\\nhttp://eminem.com\\\\nhttp://facebook.com/eminem\\\\nhttp://twitter.com/eminem\\\\nhttp://instagram.com/eminem\\\\nhttp://eminem.tumblr.com\\\\nhttp://shadyrecords.com\\\\nhttp://facebook.com/shadyrecords\\\\nhttp://twitter.com/shadyrecords\\\\nhttp://instagram.com/shadyrecords\\\\nhttp://trustshady.tumblr.com\\\\n\\\\nMusic video by Eminem performing Walk On Water. (C) 2017 Aftermath Records\\\\nhttp://vevo.ly/gA7xKt\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA_DF = spark.read.schema(NASchema).option(\"header\", \"true\").option(\"sep\", \",\").csv(\"NA_youtube_data/*.csv\")\n",
    "NA_DF.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|trending_date|publish_time       |\n",
      "+-------------+-------------------+\n",
      "|17.14.11     |2017-11-10 18:00:03|\n",
      "|17.14.11     |2017-11-13 18:00:00|\n",
      "+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NA_DF.select(\"trending_date\",\"publish_time\").limit(2).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------------+-------------------+\n",
      "|trending_date|publish_time       |dt_trending_date|dt_publish_time    |\n",
      "+-------------+-------------------+----------------+-------------------+\n",
      "|17.14.11     |2017-11-10 18:00:03|2017-11-14      |2017-11-10 18:00:03|\n",
      "+-------------+-------------------+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, to_timestamp, col, concat, lit\n",
    "\n",
    "NA_DF.select(\"trending_date\",\"publish_time\")\\\n",
    "        .limit(1)\\\n",
    "        .withColumn(\"dt_trending_date\", to_date(concat(lit(\"20\"), col(\"trending_date\")),\"y.d.M\"))\\\n",
    "        .withColumn(\"dt_publish_time\", to_timestamp(col(\"publish_time\")))\\\n",
    "        .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------------+-------------------+\n",
      "|trending_date|publish_time       |dt_trending_date|dt_publish_time    |\n",
      "+-------------+-------------------+----------------+-------------------+\n",
      "|17.14.11     |2017-11-10 18:00:03|2017-11-14      |2017-11-10 18:00:03|\n",
      "|17.14.11     |2017-11-13 18:00:00|2017-11-14      |2017-11-13 18:00:00|\n",
      "|17.14.11     |2017-11-12 20:05:24|2017-11-14      |2017-11-12 20:05:24|\n",
      "|17.14.11     |2017-11-12 19:01:41|2017-11-14      |2017-11-12 19:01:41|\n",
      "|17.14.11     |2017-11-09 12:04:14|2017-11-14      |2017-11-09 12:04:14|\n",
      "|17.14.11     |2017-11-13 08:37:51|2017-11-14      |2017-11-13 08:37:51|\n",
      "|17.14.11     |2017-11-13 00:52:13|2017-11-14      |2017-11-13 00:52:13|\n",
      "|17.14.11     |2017-11-13 18:13:01|2017-11-14      |2017-11-13 18:13:01|\n",
      "|17.14.11     |2017-11-12 21:19:24|2017-11-14      |2017-11-12 21:19:24|\n",
      "|17.14.11     |2017-11-10 15:10:46|2017-11-14      |2017-11-10 15:10:46|\n",
      "|17.14.11     |2017-11-10 20:00:02|2017-11-14      |2017-11-10 20:00:02|\n",
      "|17.14.11     |2017-11-12 16:00:05|2017-11-14      |2017-11-12 16:00:05|\n",
      "|17.14.11     |2017-11-12 17:00:01|2017-11-14      |2017-11-12 17:00:01|\n",
      "|17.14.11     |2017-11-11 17:41:15|2017-11-14      |2017-11-11 17:41:15|\n",
      "|17.14.11     |2017-11-12 23:00:01|2017-11-14      |2017-11-12 23:00:01|\n",
      "|17.14.11     |2017-11-11 17:00:44|2017-11-14      |2017-11-11 17:00:44|\n",
      "|17.14.11     |2017-11-13 02:30:01|2017-11-14      |2017-11-13 02:30:01|\n",
      "|17.14.11     |2017-11-10 20:06:23|2017-11-14      |2017-11-10 20:06:23|\n",
      "|17.14.11     |2017-11-13 15:00:03|2017-11-14      |2017-11-13 15:00:03|\n",
      "|17.14.11     |2017-11-12 13:20:39|2017-11-14      |2017-11-12 13:20:39|\n",
      "+-------------+-------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, to_timestamp, col, concat, lit\n",
    "\n",
    "dataframe = NA_DF.select(\"trending_date\",\"publish_time\")\\\n",
    "        .withColumn(\"dt_trending_date\", to_date(concat(lit(\"20\"), col(\"trending_date\")),\"y.d.M\"))\\\n",
    "        .withColumn(\"dt_publish_time\", to_timestamp(col(\"publish_time\")))\\\n",
    "        .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately, the output of the above query is a NoneType, and we cannot use it for any aggregations, or append to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_994/1460516063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'schema'"
     ]
    }
   ],
   "source": [
    "dataframe.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This DataFrame has **137516 rows**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"This DataFrame has **%d rows**.\" % NA_DF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video_id',\n",
       " 'trending_date',\n",
       " 'title',\n",
       " 'channel_title',\n",
       " 'category_id',\n",
       " 'publish_time',\n",
       " 'tags',\n",
       " 'views',\n",
       " 'likes',\n",
       " 'dislikes',\n",
       " 'comment_count',\n",
       " 'thumbnail_link',\n",
       " 'comments_disabled',\n",
       " 'ratings_disabled',\n",
       " 'video_error_or_removed',\n",
       " 'description']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- publish_time: timestamp (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- comments_disabled: boolean (nullable = true)\n",
      " |-- ratings_disabled: boolean (nullable = true)\n",
      " |-- video_error_or_removed: boolean (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This DataFrame has **137516 rows**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "NA_DF.printSchema()\n",
    "display(Markdown(\"This DataFrame has **%d rows**.\" % NA_DF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(video_id='kzwfHumJyYc', trending_date='17.14.11', title='Sharry Mann: Cute Munda ( Song Teaser) | Parmish Verma | Releasing on 17 November', channel_title='Lokdhun Punjabi', category_id=1, publish_time=datetime.datetime(2017, 11, 12, 13, 20, 39), tags='\"sharry mann|\"\"sharry mann new song\"\"|\"\"sharry mann cute munda\"\"|\"\"sharry mann latest song\"\"|\"\"sharry mann punjabi song 2017\"\"|\"\"parmish verma\"\"|\"\"parmish verma new song\"\"|\"\"parmish verma sharry mann\"\"|\"\"parmish verma sharry mann new song\"\"|\"\"parmish verma cute munda\"\"|\"\"new punjabi song 2017\"\"|\"\"punjabi song 2017\"\"|\"\"parmish verma new song 2017\"\"|\"\"parmish verma latest song 2017\"\"|\"\"punjabi songs 2017\"\"\"', views=1096327, likes=33966, dislikes=798, comment_count=882, thumbnail_link='https://i.ytimg.com/vi/kzwfHumJyYc/default.jpg', comments_disabled=False, ratings_disabled=False, video_error_or_removed=False, description='Presenting Sharry Mann latest Punjabi Song  Cute Munda Teaser . The music of new punjabi song is given by Gift Rulers while lyrics are penned by Zaildar Pargat Singh. The video is directed by Parmish Verma. \\\\nEnjoy and stay connected with us!! \\\\n\\\\nSong : Cute Munda\\\\nSinger : Sharry Mann\\\\nStarring : Sharry Mann, Rumman & Parmish Verma\\\\nMusic : Gift Rulers\\\\nLyrics : Zaildar Pargat Singh\\\\nConcept, Screenplay & Direction : Parmish Verma\\\\nOnline Promotions : Gold Media\\\\nCopyright: Lokdhun\\\\n\\\\nFull Song Releasing on 17th November\\\\n\\\\n\\\\nFor more new Punjabi songs, latest Punjabi videos, funny Punjabi comedy scenes and new Punjabi movies, subscribe our channel - http://goo.gl/NnoXVB\\\\n\\\\n\\\\nLike us on Facebook - https://www.facebook.com/LokdhunPunjabiOfficial/\\\\nFollow us on Twitter - https://twitter.com/lokdhunpunjabi\\\\nFollow us on Instagram - https://www.instagram.com/lokdhunpunjabi\\\\nVisit us on https://www.lokdhun.com')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AS_DF = spark.read.schema(NASchema).option(\"header\", \"true\").option(\"sep\", \",\").csv(\"ASIA_youtube_data/*.csv\")\n",
    "AS_DF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(video_id='Ro6eob0LrCY', trending_date='17.14.11', title='Malika LePen : Femme de Gauche - Trailer', channel_title='Le Raptor Dissident', category_id=24, publish_time=datetime.datetime(2017, 11, 13, 18, 32, 55), tags='\"Raptor\"\"|\"\"Dissident\"\"|\"\"Expliquez\"\"|\"\"moi\"\"|\"\"cette\"\"|\"\"merde\"', views=212702, likes=29282, dislikes=1108, comment_count=3817, thumbnail_link='https://i.ytimg.com/vi/Ro6eob0LrCY/default.jpg', comments_disabled=False, ratings_disabled=False, video_error_or_removed=False, description=\"Dimanche.\\\\n18h30.\\\\nSoyez présents pour la vidéo la plus réalistiquement haineuse du YouTube Game.\\\\n\\\\nStrike sous 24h garanti.\\\\n\\\\nMontage de NastyTanooki : https://www.youtube.com/channel/UCJvYnKvJZSIz-2deI7Xppww\\\\n\\\\n------------------------------------------------------------------------------------------------\\\\n\\\\nRAPTORCOACHING PRO : raptorcoachingpro@gmail.com\\\\n\\\\nSi tu pratiques la musculation et que tu es intéressé(e) par un Programme/Diète Personnalisés + Suivi, envoie nous un mail avec ton Nom/Âge/Objectif et le coach s'occupera de toi. Le training sera réalisé en fonction des objectifs aussi bien muscu prise de muscle/sèche que prépa sportive/concours.\\\\n\\\\nPROZIS : -10% sur tout le site http://prozis.com/lb5 avec le coupon COACHINGPRO10\\\\n\\\\n------------------------------------------------------------------------------------------------\\\\n\\\\nRejoins la dissidence jurassique sur les réseaux sociaux :\\\\n\\\\nFACEBOOK : https://www.facebook.com/LeRaptorDissident\\\\n\\\\nTWITTER : https://twitter.com/RaptorDissident\\\\n\\\\nSNAPCHAT : raptorvswild\\\\n\\\\nINSTAGRAM : raptorvsfonte\\\\n\\\\nTIPEE D'OR : https://www.tipeee.com/le-raptor-dissident\\\\n\\\\n------------------------------------------------------------------------------------------------\\\\n\\\\nSources :\\\\n\\\\nMusique : https://www.youtube.com/watch?v=7vn5BD0oadM\\\\n\\\\nMa Bannière et mon Avatar YouTube : LeDessinator https://www.youtube.com/channel/UCXLIl-l_zi1lCVrJHLJqJew\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EU_DF = spark.read.schema(NASchema).option(\"header\", \"true\").option(\"sep\", \",\").csv(\"EU/*.csv\")\n",
    "EU_DF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|            views|             likes|          dislikes|     comment_count|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|           122281|            122281|            122281|            122281|\n",
      "|   mean|1287309.052223976| 43350.59626597755|2161.7377924616253|   5189.3286773906|\n",
      "| stddev|4879842.267669742|161800.71685038836| 21075.12560555939|26380.843898437804|\n",
      "|    min|              157|                 0|                 0|                 0|\n",
      "|    25%|            67952|              1144|                59|               190|\n",
      "|    50%|           283305|              7123|               257|               926|\n",
      "|    75%|           928038|             28177|               965|              3237|\n",
      "|    max|        225211923|           5613827|           1674420|           1361580|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "NA_NUM_DF= NA_DF[['views', 'likes', 'dislikes','comment_count']]\n",
    "NA_NUM_DF.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "NA_PD = NA_DF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North America Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "|summary|             likes|            views|          dislikes|     comment_count|\n",
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "|  count|            122281|           122281|            122281|            122281|\n",
      "|   mean| 43350.59626597755|1287309.052223976|2161.7377924616253|   5189.3286773906|\n",
      "| stddev|161800.71685038836|4879842.267669742| 21075.12560555939|26380.843898437804|\n",
      "|    min|                 0|              157|                 0|                 0|\n",
      "|    max|           5613827|        225211923|           1674420|           1361580|\n",
      "+-------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "NA_DF.describe('likes', 'views', 'dislikes', 'comment_count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EUROPE statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "|summary|            likes|             views|         dislikes|     comment_count|\n",
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "|  count|            79640|             79640|            79640|             79640|\n",
      "|   mean| 74624.6488448016|  3103592.36084882|4136.601104972376| 7332.636300853842|\n",
      "| stddev|259175.3514812264|1.36222260989259E7|36697.65666761797|37241.603765286694|\n",
      "|    min|                0|               223|                0|                 0|\n",
      "|    max|          5613827|         424538912|          1944971|           1626501|\n",
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EU_DF.describe('likes', 'views', 'dislikes', 'comment_count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASIA statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|             likes|             views|          dislikes|     comment_count|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|             57873|             57873|             57873|             57873|\n",
      "|   mean|20337.620323812487|  777363.601627702|1204.7476543465864|2151.9194961380954|\n",
      "| stddev|  93095.2819554454|2699519.1951408307|13026.639994488636|14912.022999546438|\n",
      "|    min|                 0|               798|                 0|                 0|\n",
      "|    max|           4470923|         125432237|           1545017|            905925|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AS_stats = AS_DF.describe('likes', 'views', 'dislikes', 'comment_count')\n",
    "AS_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORTH AMERICA Summary of columns views, likes, dislikes, comment_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|            views|             likes|          dislikes|     comment_count|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|           122281|            122281|            122281|            122281|\n",
      "|   mean|1287309.052223976| 43350.59626597755|2161.7377924616253|   5189.3286773906|\n",
      "| stddev|4879842.267669742|161800.71685038836| 21075.12560555939|26380.843898437804|\n",
      "|    min|              157|                 0|                 0|                 0|\n",
      "|    25%|            67952|              1144|                59|               190|\n",
      "|    50%|           283305|              7123|               257|               926|\n",
      "|    75%|           928038|             28177|               965|              3237|\n",
      "|    max|        225211923|           5613827|           1674420|           1361580|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n",
      "EUROPE Summary of columns views, likes, dislikes, comment_count\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "|summary|             views|            likes|         dislikes|     comment_count|\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "|  count|             79640|            79640|            79640|             79640|\n",
      "|   mean|  3103592.36084882| 74624.6488448016|4136.601104972376| 7332.636300853842|\n",
      "| stddev|1.36222260989259E7|259175.3514812264|36697.65666761797|37241.603765286694|\n",
      "|    min|               223|                0|                0|                 0|\n",
      "|    25%|             52130|             1161|               49|               154|\n",
      "|    50%|            252599|             6601|              253|               736|\n",
      "|    75%|           1310105|            38507|             1265|              3566|\n",
      "|    max|         424538912|          5613827|          1944971|           1626501|\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "\n",
      "ASIA Summary of columns views, likes, dislikes, comment_count\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|             views|             likes|          dislikes|     comment_count|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|             57873|             57873|             57873|             57873|\n",
      "|   mean|  777363.601627702|20337.620323812487|1204.7476543465864|2151.9194961380954|\n",
      "| stddev|2699519.1951408307|  93095.2819554454|13026.639994488636|14912.022999546438|\n",
      "|    min|               798|                 0|                 0|                 0|\n",
      "|    25%|             63428|               438|                45|                50|\n",
      "|    50%|            185699|              1796|               180|               239|\n",
      "|    75%|            550451|              7779|               651|               928|\n",
      "|    max|         125432237|           4470923|           1545017|            905925|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n",
      "Most VIDEOS PER Category in NA:\n",
      "+-----------+-----+\n",
      "|category_id|Total|\n",
      "+-----------+-----+\n",
      "|         24|36902|\n",
      "|         22|15474|\n",
      "|       null|15235|\n",
      "|         10|13574|\n",
      "|         25| 9759|\n",
      "|         17| 9011|\n",
      "|         23| 8972|\n",
      "|         26| 8620|\n",
      "|          1| 5703|\n",
      "|         28| 4087|\n",
      "|         27| 3179|\n",
      "|         20| 3155|\n",
      "|         15| 1372|\n",
      "|          2|  989|\n",
      "|         19|  911|\n",
      "|         29|  383|\n",
      "|         43|  184|\n",
      "|         30|    6|\n",
      "+-----------+-----+\n",
      "\n",
      "Most VIDEOS PER Category  in EU:\n",
      "+-----------+-----+\n",
      "|category_id|Total|\n",
      "+-----------+-----+\n",
      "|         24|18943|\n",
      "|         10|17700|\n",
      "|       null| 9793|\n",
      "|         22| 8645|\n",
      "|         17| 6249|\n",
      "|         23| 6171|\n",
      "|         25| 4977|\n",
      "|          1| 4734|\n",
      "|         26| 4289|\n",
      "|         20| 3247|\n",
      "|         28| 1320|\n",
      "|         27| 1226|\n",
      "|          2|  817|\n",
      "|         15|  771|\n",
      "|         19|  215|\n",
      "|         29|  204|\n",
      "|         43|  119|\n",
      "|         30|   11|\n",
      "|         44|    2|\n",
      "+-----------+-----+\n",
      "\n",
      "Most VIDEOS PER Category  in ASIA:\n",
      "+-----------+-----+\n",
      "|category_id|Total|\n",
      "+-----------+-----+\n",
      "|         24|22971|\n",
      "|         25| 6633|\n",
      "|         22| 6539|\n",
      "|         10| 5148|\n",
      "|         23| 4172|\n",
      "|          1| 2878|\n",
      "|         17| 2768|\n",
      "|       null| 2097|\n",
      "|         26| 1644|\n",
      "|         27| 1339|\n",
      "|         15| 1130|\n",
      "|         20| 1096|\n",
      "|         28|  710|\n",
      "|          2|  352|\n",
      "|         43|  205|\n",
      "|         19|  151|\n",
      "|         29|  123|\n",
      "|         30|   16|\n",
      "|          7|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first, lit\n",
    "\n",
    "\n",
    "print (\"NORTH AMERICA Summary of columns views, likes, dislikes, comment_count\")\n",
    "NA_DF.select('views', 'likes', 'dislikes','comment_count').summary().show()\n",
    "\n",
    "print (\"EUROPE Summary of columns views, likes, dislikes, comment_count\")\n",
    "EU_DF.select('views', 'likes', 'dislikes','comment_count').summary().show()\n",
    "\n",
    "print (\"ASIA Summary of columns views, likes, dislikes, comment_count\")\n",
    "AS_DF.select('views', 'likes', 'dislikes','comment_count').summary().show()\n",
    "\n",
    "\n",
    "NA_CAT_DF = NA_DF.groupBy(\"category_id\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "EU_CAT_DF = EU_DF.groupBy(\"category_id\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "AS_CAT_DF = AS_DF.groupBy(\"category_id\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "\n",
    "print (\"Most VIDEOS PER Category in NA:\")\n",
    "NA_CAT_DF.orderBy(col(\"Total\").desc()).show()\n",
    "\n",
    "print(\"Most VIDEOS PER Category  in EU:\")\n",
    "EU_CAT_DF.orderBy(col(\"Total\").desc()).show()\n",
    "\n",
    "print(\"Most VIDEOS PER Category  in ASIA:\")\n",
    "AS_CAT_DF.orderBy(col(\"Total\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORTH AMERICA Summary of columns views, likes, dislikes, comment_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|            views|             likes|          dislikes|     comment_count|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|           122281|            122281|            122281|            122281|\n",
      "|   mean|1287309.052223976| 43350.59626597755|2161.7377924616253|   5189.3286773906|\n",
      "| stddev|4879842.267669742|161800.71685038836| 21075.12560555939|26380.843898437804|\n",
      "|    min|              157|                 0|                 0|                 0|\n",
      "|    25%|            67952|              1144|                59|               190|\n",
      "|    50%|           283305|              7123|               257|               926|\n",
      "|    75%|           928038|             28177|               965|              3237|\n",
      "|    max|        225211923|           5613827|           1674420|           1361580|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n",
      "EUROPE Summary of columns views, likes, dislikes, comment_count\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "|summary|             views|            likes|         dislikes|     comment_count|\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "|  count|             79640|            79640|            79640|             79640|\n",
      "|   mean|  3103592.36084882| 74624.6488448016|4136.601104972376| 7332.636300853842|\n",
      "| stddev|1.36222260989259E7|259175.3514812264|36697.65666761797|37241.603765286694|\n",
      "|    min|               223|                0|                0|                 0|\n",
      "|    25%|             52130|             1161|               49|               154|\n",
      "|    50%|            252599|             6601|              253|               736|\n",
      "|    75%|           1310105|            38507|             1265|              3566|\n",
      "|    max|         424538912|          5613827|          1944971|           1626501|\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "\n",
      "ASIA Summary of columns views, likes, dislikes, comment_count\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|             views|             likes|          dislikes|     comment_count|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|             57873|             57873|             57873|             57873|\n",
      "|   mean|  777363.601627702|20337.620323812487|1204.7476543465864|2151.9194961380954|\n",
      "| stddev|2699519.1951408307|  93095.2819554454|13026.639994488636|14912.022999546438|\n",
      "|    min|               798|                 0|                 0|                 0|\n",
      "|    25%|             63428|               438|                45|                50|\n",
      "|    50%|            185699|              1796|               180|               239|\n",
      "|    75%|            550451|              7779|               651|               928|\n",
      "|    max|         125432237|           4470923|           1545017|            905925|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n",
      "Most views per Category in NA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|category_id| sum(views)|\n",
      "+-----------+-----------+\n",
      "|         10|57472455667|\n",
      "|         24|38303178040|\n",
      "|          1|10685137184|\n",
      "|         23| 9620512481|\n",
      "|         22| 9374921560|\n",
      "|         17| 8791446839|\n",
      "|         26| 6114979104|\n",
      "|         28| 5115710691|\n",
      "|         20| 3804712783|\n",
      "|         25| 3579824789|\n",
      "|         27| 1755608642|\n",
      "|         15| 1045873184|\n",
      "|          2|  769947652|\n",
      "|         19|  502717086|\n",
      "|         29|  336176021|\n",
      "|         43|  123116002|\n",
      "|         30|   17120490|\n",
      "|       null|       null|\n",
      "+-----------+-----------+\n",
      "\n",
      "Most views per Category in EU:\n",
      "+-----------+------------+\n",
      "|category_id|  sum(views)|\n",
      "+-----------+------------+\n",
      "|         10|176187312291|\n",
      "|         24| 33565783270|\n",
      "|          1|  9281224644|\n",
      "|         22|  7035131362|\n",
      "|         23|  5858346792|\n",
      "|         17|  5338547233|\n",
      "|         20|  2193779708|\n",
      "|         28|  2103380550|\n",
      "|         25|  1904176938|\n",
      "|         26|  1658499640|\n",
      "|         15|   584659814|\n",
      "|         27|   565033113|\n",
      "|         29|   412288398|\n",
      "|          2|   257949454|\n",
      "|         19|   142534073|\n",
      "|         43|    80407184|\n",
      "|         30|     1028214|\n",
      "|         44|       12940|\n",
      "|       null|        null|\n",
      "+-----------+------------+\n",
      "\n",
      "Most views per Category in ASIA:\n",
      "+-----------+-----------+\n",
      "|category_id| sum(views)|\n",
      "+-----------+-----------+\n",
      "|         24|17886659218|\n",
      "|         10|11221188864|\n",
      "|          1| 4158731595|\n",
      "|         23| 3168645984|\n",
      "|         25| 2180494980|\n",
      "|         17| 1960675173|\n",
      "|         22| 1951591561|\n",
      "|         26|  845760585|\n",
      "|         28|  668883227|\n",
      "|         20|  448248336|\n",
      "|         27|  155240593|\n",
      "|         43|  139581891|\n",
      "|         15|   75561585|\n",
      "|          2|   53678603|\n",
      "|         30|   49040020|\n",
      "|         19|   16145741|\n",
      "|         29|    8235761|\n",
      "|       null|       null|\n",
      "|          7|       null|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first, lit\n",
    "\n",
    "\n",
    "print (\"NORTH AMERICA Summary of columns views, likes, dislikes, comment_count\")\n",
    "NA_DF.select('views', 'likes', 'dislikes','comment_count').summary().show()\n",
    "\n",
    "print (\"EUROPE Summary of columns views, likes, dislikes, comment_count\")\n",
    "EU_DF.select('views', 'likes', 'dislikes','comment_count').summary().show()\n",
    "\n",
    "print (\"ASIA Summary of columns views, likes, dislikes, comment_count\")\n",
    "AS_DF.select('views', 'likes', 'dislikes','comment_count').summary().show()\n",
    "\n",
    "print(\"Most views per Category in NA:\")\n",
    "NA_CATviews_DF = NA_DF.groupBy(\"category_id\")\n",
    "NA_VIEWS = NA_CATviews_DF.agg({'views': 'sum'})\n",
    "NA_VIEWS.orderBy(col('sum(views)').desc()).show()\n",
    "\n",
    "print(\"Most views per Category in EU:\")\n",
    "EU_CATviews_DF = EU_DF.groupBy(\"category_id\")\n",
    "EU_VIEWS = EU_CATviews_DF.agg({'views': 'sum'})\n",
    "EU_VIEWS.orderBy(col('sum(views)').desc()).show()\n",
    "\n",
    "print(\"Most views per Category in ASIA:\")\n",
    "AS_CATviews_DF = AS_DF.groupBy(\"category_id\")\n",
    "AS_VIEWS = AS_CATviews_DF.agg({'views': 'sum'})\n",
    "AS_VIEWS.orderBy(col('sum(views)').desc()).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most comments per Category in NA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|category_id|sum(comment_count)|\n",
      "+-----------+------------------+\n",
      "|         10|         199476213|\n",
      "|         24|         158568420|\n",
      "|         23|          49022945|\n",
      "|         22|          48901087|\n",
      "|         26|          35174605|\n",
      "|          1|          30021806|\n",
      "|         20|          27292905|\n",
      "|         17|          22059593|\n",
      "|         28|          20080654|\n",
      "|         25|          17627896|\n",
      "|         29|           8992924|\n",
      "|         27|           8706312|\n",
      "|         15|           4650304|\n",
      "|          2|           2168744|\n",
      "|         19|           1625222|\n",
      "|         43|            172691|\n",
      "|         30|             13979|\n",
      "|       null|              null|\n",
      "+-----------+------------------+\n",
      "\n",
      "Most comments per Category in EU:\n",
      "+-----------+------------------+\n",
      "|category_id|sum(comment_count)|\n",
      "+-----------+------------------+\n",
      "|         10|         318459429|\n",
      "|         24|         132627364|\n",
      "|         23|          25855630|\n",
      "|         22|          22817967|\n",
      "|          1|          18431666|\n",
      "|         17|          14631644|\n",
      "|         25|          11282705|\n",
      "|         29|           9521383|\n",
      "|         20|           9214587|\n",
      "|         26|           9115654|\n",
      "|         28|           6955428|\n",
      "|         27|           2404977|\n",
      "|         15|           1592288|\n",
      "|          2|            713058|\n",
      "|         19|            220069|\n",
      "|         43|            125839|\n",
      "|         30|              1467|\n",
      "|         44|                 0|\n",
      "|       null|              null|\n",
      "+-----------+------------------+\n",
      "\n",
      "Most comments per Category in ASIA:\n",
      "+-----------+------------------+\n",
      "|category_id|sum(comment_count)|\n",
      "+-----------+------------------+\n",
      "|         24|          48251591|\n",
      "|         10|          28724909|\n",
      "|         23|          15036393|\n",
      "|         28|          10294075|\n",
      "|          1|           6670447|\n",
      "|         22|           4331084|\n",
      "|         17|           3769422|\n",
      "|         25|           3496566|\n",
      "|         20|           1239672|\n",
      "|         26|           1116633|\n",
      "|         27|            989384|\n",
      "|         15|            268923|\n",
      "|          2|            132103|\n",
      "|         43|            104880|\n",
      "|         19|             51791|\n",
      "|         30|             36941|\n",
      "|         29|             23223|\n",
      "|       null|              null|\n",
      "|          7|              null|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first, lit\n",
    "\n",
    "print(\"Most comments per Category in NA:\")\n",
    "NA_CAT_COM = NA_DF.groupBy(\"category_id\")\n",
    "NA_COMMENT = NA_CAT_COM.agg({'comment_count': 'sum'})\n",
    "NA_COMMENT.orderBy(col('sum(comment_count)').desc()).show()\n",
    "\n",
    "print(\"Most comments per Category in EU:\")\n",
    "EU_CAT_COM = EU_DF.groupBy(\"category_id\")\n",
    "EU_COMMENT = EU_CAT_COM.agg({'comment_count': 'sum'})\n",
    "EU_COMMENT.orderBy(col('sum(comment_count)').desc()).show()\n",
    "\n",
    "print(\"Most comments per Category in ASIA:\")\n",
    "AS_CAT_COM = AS_DF.groupBy(\"category_id\")\n",
    "AS_COMMENT = AS_CAT_COM.agg({'comment_count': 'sum'})\n",
    "AS_COMMENT.orderBy(col('sum(comment_count)').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most dislikes per Category in NA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|category_id|sum(dislikes)|\n",
      "+-----------+-------------+\n",
      "|         10|     81234533|\n",
      "|         24|     79918306|\n",
      "|         22|     22888255|\n",
      "|         23|     15003594|\n",
      "|         20|     12569587|\n",
      "|          1|      9703060|\n",
      "|         17|      9699371|\n",
      "|         25|      8401469|\n",
      "|         26|      7996781|\n",
      "|         28|      6615417|\n",
      "|         29|      6141769|\n",
      "|         27|      2212828|\n",
      "|         15|       776095|\n",
      "|          2|       524538|\n",
      "|         19|       496541|\n",
      "|         43|       145035|\n",
      "|         30|        12280|\n",
      "|       null|         null|\n",
      "+-----------+-------------+\n",
      "\n",
      "Most dislikes per Category in EU:\n",
      "+-----------+-------------+\n",
      "|category_id|sum(dislikes)|\n",
      "+-----------+-------------+\n",
      "|         10|    169142554|\n",
      "|         24|     98457729|\n",
      "|         22|     13763281|\n",
      "|         17|     12060511|\n",
      "|         23|      8021809|\n",
      "|          1|      7285678|\n",
      "|         29|      6667967|\n",
      "|         25|      4556217|\n",
      "|         20|      3401916|\n",
      "|         26|      2250736|\n",
      "|         28|      2134907|\n",
      "|         27|       794512|\n",
      "|         15|       410651|\n",
      "|          2|       333450|\n",
      "|         43|       110242|\n",
      "|         19|        45695|\n",
      "|         30|         1048|\n",
      "|         44|            9|\n",
      "|       null|         null|\n",
      "+-----------+-------------+\n",
      "\n",
      "Most dislikes per Category in ASIA:\n",
      "+-----------+-------------+\n",
      "|category_id|sum(dislikes)|\n",
      "+-----------+-------------+\n",
      "|         24|     30067016|\n",
      "|         10|     16914430|\n",
      "|         23|      7423434|\n",
      "|          1|      4610278|\n",
      "|         25|      3037945|\n",
      "|         22|      2647518|\n",
      "|         17|      1694719|\n",
      "|         28|      1074431|\n",
      "|         26|      1010970|\n",
      "|         20|       565782|\n",
      "|         27|       266843|\n",
      "|         43|       226268|\n",
      "|         15|        53280|\n",
      "|          2|        43868|\n",
      "|         19|        39107|\n",
      "|         30|        34182|\n",
      "|         29|        12290|\n",
      "|       null|         null|\n",
      "|          7|         null|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first, lit\n",
    "\n",
    "\n",
    "print(\"Most dislikes per Category in NA:\")\n",
    "NA_CAT_DIS = NA_DF.groupBy(\"category_id\")\n",
    "NA_DISLIKE = NA_CAT_DIS.agg({'dislikes': 'sum'})\n",
    "NA_DISLIKE.orderBy(col('sum(dislikes)').desc()).show()\n",
    "\n",
    "print(\"Most dislikes per Category in EU:\")\n",
    "EU_CAT_DIS = EU_DF.groupBy(\"category_id\")\n",
    "EU_DISLIKE = EU_CAT_DIS.agg({'dislikes': 'sum'})\n",
    "EU_DISLIKE.orderBy(col('sum(dislikes)').desc()).show()\n",
    "\n",
    "print(\"Most dislikes per Category in ASIA:\")\n",
    "AS_CAT_DIS = AS_DF.groupBy(\"category_id\")\n",
    "AS_DISLIKE = AS_CAT_DIS.agg({'dislikes': 'sum'})\n",
    "AS_DISLIKE.orderBy(col('sum(dislikes)').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
